{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e294d0",
   "metadata": {},
   "source": [
    "### From REST to reasoning: ingest, index, and query with dlt and Cognee Homework\n",
    "\n",
    "* Video: https://www.youtube.com/watch?v=MNt_KK32gys\n",
    "\n",
    "#### Resources\n",
    "\n",
    "* [Slides](https://docs.google.com/presentation/d/1oHQilxEVqGGW4S2ctNEE0wHY2LgcjYLaRUziAoinsis/edit?usp=sharing)\n",
    "* [Colab Notebook](https://colab.research.google.com/drive/1vBA9OIGChcKjjg8r5hHduR0v3A5D6rmH?usp=sharing) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a592e91",
   "metadata": {},
   "source": [
    "### Question 1. dlt Version\n",
    "\n",
    "In this homework, we will load the data from our FAQ to Qdrant\n",
    "\n",
    "Let's install dlt with Qdrant support and the Qdrant client:   (note: we will also need networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a3a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"networkx\" \"dlt[qdrant]\" \"qdrant-client[fastembed]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235557c1",
   "metadata": {},
   "source": [
    "What's the version of dlt that you installed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bfbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt \n",
    "import requests \n",
    "import os\n",
    "from dlt.destinations import qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ca1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: dlt\n",
      "Version: 1.12.3\n",
      "Summary: dlt is an open-source python-first scalable data loading library that does not require any backend to run.\n",
      "Home-page: https://github.com/dlt-hub\n",
      "Author: \n",
      "Author-email: \"dltHub Inc.\" <services@dlthub.com>\n",
      "License-Expression: Apache-2.0\n",
      "Location: /home/codespace/.python/current/lib/python3.12/site-packages\n",
      "Requires: click, fsspec, gitpython, giturlparse, hexbytes, humanize, jsonpath-ng, orjson, packaging, pathvalidate, pendulum, pluggy, pytz, pyyaml, requests, requirements-parser, rich-argparse, semver, setuptools, simplejson, sqlglot, tenacity, tomlkit, typing-extensions, tzdata\n",
      "Required-by: cognee\n"
     ]
    }
   ],
   "source": [
    "!pip show dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3c605",
   "metadata": {},
   "source": [
    "### A1. dlt version 1.12.3 is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ae93f",
   "metadata": {},
   "source": [
    "### dlt Resource\n",
    "\n",
    "For reading the FAQ data, we have this helper function:\n",
    "\n",
    "(Note:  the yield transforms the python function into a generator function, which is an object that produces a sequence of values, one at a time, instead of computing and storing all values in memory at once.  yield preserves the function stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5701303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fd4d6",
   "metadata": {},
   "source": [
    "Annotate the function with @dlt.resource.  We will use it when creating a dlt pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b6a66",
   "metadata": {},
   "source": [
    "### Question 2. dlt pipeline\n",
    "\n",
    "Now let's create a pipeline.\n",
    "\n",
    "We need to define a destination for that.  Let's use the qdrant one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36b3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_destination = qdrant(\n",
    "    qd_path=\"db.qdrant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519ad4b",
   "metadata": {},
   "source": [
    "In this case, we tell dlt (and Qdrant) to create a folder with our data, and the name for it will be db.qdrant\n",
    "\n",
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1512710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-07-05 18:10:09.107155+00:00 and COMPLETED in 6.27 seconds with 4 steps.\n",
      "Step extract COMPLETED in 0.30 seconds.\n",
      "\n",
      "Load package 1751739011.2645357 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.09 seconds.\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- zoomcamp_data: 948 row(s)\n",
      "\n",
      "Load package 1751739011.2645357 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 3.74 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.72 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /workspaces/llm-zoomcamp2025/workshops/dlt/db.qdrant location to store data\n",
      "Load package 1751739011.2645357 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 6.27 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.72 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /workspaces/llm-zoomcamp2025/workshops/dlt/db.qdrant location to store data\n",
      "Load package 1751739011.2645357 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088ee1e",
   "metadata": {},
   "source": [
    "How many rows were inserted into the zoomcamp_data collection?\n",
    "\n",
    "Look for \"Normalized data for the following tables:\" in the trace output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf2a3b",
   "metadata": {},
   "source": [
    "### A2. 948 rows were inserted into the zoomcamp_data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc92a0",
   "metadata": {},
   "source": [
    "### Question 3. Embeddings\n",
    "\n",
    "When inserting the data, an embedding model was used.  Which one?\n",
    "\n",
    "You can find this out by inspecting the meta.json file created in the target folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb76ae",
   "metadata": {},
   "source": [
    "### A3. \"fast-bge-small-en\" was the embedding model used for this exercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
